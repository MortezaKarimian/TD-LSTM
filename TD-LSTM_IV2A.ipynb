{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_g2Ss23Gvrni"
   },
   "outputs": [],
   "source": [
    "basePath='D:\\\\PM\\\\IV2A\\\\'\n",
    "dbType='IV2A_Imagery'\n",
    "random_seed = 32654"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "cicCF8Wvji5J",
    "outputId": "1c95747f-13aa-45f3-f6db-a35ee203cb44",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "1EODUBQj-zPU"
   },
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "IfQXvs0jvxQv",
    "outputId": "3011cf81-aa43-4efb-cf57-26b6858010bc"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#!pip uninstall tensorflow==2.2.0 --yes\n",
    "!pip uninstall keras --yes\n",
    "\n",
    "      #!pip install argcomplete\n",
    "!pip install keras==2.2.4\n",
    "#!pip install tensorflow==1.10\n",
    "\n",
    "\n",
    "\n",
    "!pip install ipython-autotime\n",
    "!pip install plot_keras_history\n",
    "\n",
    "print('~'*50)\n",
    "\n",
    "\n",
    "%tensorflow_version 1.10\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "print('~'*50)\n",
    "\n",
    "print('ok')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "u1chUhOulg1X",
    "outputId": "373a27bc-a38c-4d2f-9739-d3e50c14e085"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 1.10\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "oIFR6K901cBV",
    "outputId": "dcd48fef-1da7-4413-8d53-350f11764a07"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "90gcZITNGVnl"
   },
   "outputs": [],
   "source": [
    "#%load_ext autotime\n",
    "#%unload_ext autotime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "h11kVYItZ-qn"
   },
   "source": [
    "## Prepare Data 25920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "btEKncbgaFz0",
    "outputId": "7c5323e9-2261-4d38-e71f-739be15fc605"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "def prepare_data():\n",
    "  #~~~~~~~~~~~~~~~~~~~~~~~~~~~     prepare data   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "  \n",
    "\n",
    "  with open('D:\\PM\\MMCNN_2A_data_raw.pkl','rb') as f: #read\n",
    "    _Data = pkl.load(f)\n",
    "  \n",
    "  print(_Data.shape)\n",
    "  print('-------------------------------------------')\n",
    "\n",
    "\n",
    "  with open('D:\\PM\\MMCNN_2A_label_raw.pkl','rb') as f: #read\n",
    "    _Target = pkl.load(f)\n",
    "  \n",
    "  print(_Target.shape)\n",
    "  print('-------------------------------------------')\n",
    "\n",
    "\n",
    "  _Data = _Data.reshape( _Data.shape[0] , 1000 * 3 )\n",
    "\n",
    "  print(' _Data shape is : ' , _Data.shape)\n",
    "  print(' _Target shape is : ' , _Target.shape)\n",
    "  \n",
    "\n",
    "  return _Data, _Target\n",
    "\n",
    "\n",
    "\n",
    "_Data, _Target= prepare_data()\n",
    "print(' Load data ==> OK  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "bV9_BW3paQiN",
    "outputId": "7ad01166-4367-4f3e-8bdc-4920155f9dcb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_and_prepare_Data(_Data, _Target):\n",
    "  X_train, X_test, y_train, y_test = train_test_split( _Data, _Target , test_size=0.3 , random_state=random_seed  , shuffle=True)  #276159\n",
    "\n",
    "\n",
    "\n",
    "  print(\"\\x1b[31m  ....................................  \\x1b[0m\")\n",
    "  print('X_train: ', X_train.shape)\n",
    "  print('X_test: ', X_test.shape)\n",
    "  print('y_train: ', y_train.shape)\n",
    "  print('y_test: ', y_test.shape)\n",
    "  print(\"\\x1b[31m  ................. Total ...................  \\x1b[0m\")\n",
    "\n",
    "\n",
    "\n",
    "  print()\n",
    "  print(\"\\x1b[31m  .................. Summary ..................  \\x1b[0m\")\n",
    "  print('X_train: ', X_train.shape)\n",
    "  print('X_test: ', X_test.shape)\n",
    "  print('y_train: ', y_train.shape)\n",
    "  print('y_test: ', y_test.shape)\n",
    " \n",
    "\n",
    "  print(\"\\x1b[31m  ....................................  \\x1b[0m\")\n",
    "\n",
    "\n",
    "\n",
    "  import pickle as pkl\n",
    "  with open(basePath+'Imagery_temp_X_test_IV2A.pkl','wb') as f: #write\n",
    "    pkl.dump( X_test , f)\n",
    "\n",
    "  with open(basePath +'Imagery_temp_y_test_IV2A.pkl','wb') as f: #write\n",
    "    pkl.dump( y_test , f)\n",
    "\n",
    "  del  X_test, y_test\n",
    "\n",
    "\n",
    "  return X_train,y_train\n",
    "\n",
    "\n",
    "X_train, y_train= split_and_prepare_Data(_Data, _Target)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "WH6ViNM0aWdo"
   },
   "outputs": [],
   "source": [
    "del _Data, _Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "2lSAgSfcaZUJ",
    "outputId": "4ae778ef-9b1f-4bc0-ce29-0fd9c69cb62d"
   },
   "outputs": [],
   "source": [
    "print( X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "UZdbvnLQy8Tw"
   },
   "outputs": [],
   "source": [
    "y_train2=[np.where(r==1)[0][0] for r in np.array( y_train ) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "aTb_J9rhuBs6"
   },
   "source": [
    "## Reshaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "id": "q-uEtXfXB8XR"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import BaseEstimator , TransformerMixin\n",
    "\n",
    "class CustomLSTMReshaper(BaseEstimator , TransformerMixin):\n",
    "    \n",
    "     def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "     def transform(self, X, y=None):     \n",
    "        return X.reshape(( len(X), 1000,3  ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "JiZUQk7CYqN0"
   },
   "source": [
    "## Train Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "2hBfOO0IYpNL",
    "outputId": "dc604d39-2b1f-46db-abe8-2cb6eb045cf7"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "# https://medium.com/@mostafa.m.ayoub/customize-your-keras-metrics-44ac2e2980bd\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred) #precision_m\n",
    "    recall = recall_m(y_true, y_pred) #recall_m\n",
    "    return 2*( (precision*recall)/(precision+recall+K.epsilon() )   )\n",
    "\n",
    "\n",
    "def specificity_m(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "\n",
    "# implement at: https://www.sabinasz.net/unbalanced-classes-machine-learning/\n",
    "def sensitivity_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "1_Nr7yxg0sgp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "1dQPaP5F5IdJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "Fjo7iI5D3Rt8"
   },
   "source": [
    "## Test Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "id": "i2PvngAx3S3j"
   },
   "outputs": [],
   "source": [
    "\n",
    "## Metric library\n",
    "from imblearn.metrics import sensitivity_score ,specificity_score #geometric_mean_score\n",
    "\n",
    "from sklearn.metrics import(\n",
    "                            accuracy_score,\n",
    "                            precision_score, \n",
    "                            recall_score,\n",
    "                            f1_score,                                                      \n",
    "                            make_scorer,                            \n",
    "                            cohen_kappa_score\n",
    "                            )\n",
    "\n",
    "\n",
    "def make_experiments_for_tuner():\n",
    "       \n",
    "    accuracy = make_scorer(accuracy_score)\n",
    "    precision = make_scorer(precision_score , average = 'macro' )\n",
    "    recall = make_scorer(recall_score , average = 'macro')\n",
    "    f1 = make_scorer(f1_score  , average = 'macro')\n",
    "    sensitivity = make_scorer( sensitivity_score  , average = 'macro')     \n",
    "    specificity = make_scorer( specificity_score , average = 'macro')\n",
    "    kappa= make_scorer(cohen_kappa_score   )\n",
    "\n",
    "    scores_for_grid = {\n",
    "    \"accuracy\":accuracy,\n",
    "    \"precision\":precision, \n",
    "    \"recall\":recall,\n",
    "    \"f1\":f1,\n",
    "    \"sensitivity\":sensitivity,\n",
    "    \"specificity\":specificity,\n",
    "    \"kappa\":kappa\n",
    "    }\n",
    "    \n",
    "    return scores_for_grid\n",
    "\n",
    "\n",
    "def get_experiments(true_label,pred_label):\n",
    "    \n",
    "     return  {\n",
    "    \"test_accuracy\":accuracy_score(true_label,pred_label ),\n",
    "    \"test_precision\":precision_score(true_label,pred_label , average='macro' ), \n",
    "    \"test_recall\":recall_score(true_label,pred_label , average='macro' ),\n",
    "    \"test_f1\":f1_score(true_label,pred_label , average='macro' ),\n",
    "    \"test_specificity\":specificity_score(true_label,pred_label , average='macro'),    \n",
    "    \"test_sensitivity\":sensitivity_score(true_label,pred_label , average='macro'),\n",
    "    \"test_kappa\":cohen_kappa_score(true_label,pred_label   )\n",
    "     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "JVE0Vsow3TTC"
   },
   "outputs": [],
   "source": [
    "\n",
    "## Metric library\n",
    "from sklearn.metrics import(\n",
    "                            accuracy_score,\n",
    "                            precision_score, \n",
    "                            recall_score,\n",
    "                            f1_score,                                                      \n",
    "                            make_scorer,\n",
    "                            cohen_kappa_score\n",
    "                            )\n",
    "\n",
    "\n",
    "def make_experiments_for_tuner_micro():\n",
    "       \n",
    "    accuracy = make_scorer(accuracy_score)\n",
    "    precision = make_scorer(precision_score , average = 'micro' )\n",
    "    recall = make_scorer(recall_score , average = 'micro')\n",
    "    f1 = make_scorer(f1_score  , average = 'micro')\n",
    "    sensitivity = make_scorer( sensitivity_score  , average = 'micro') \n",
    "    specificity = make_scorer( specificity_score , average = 'micro')\n",
    "    kappa= make_scorer(cohen_kappa_score  )\n",
    "\n",
    "    scores_for_grid = {\n",
    "    \"accuracy\":accuracy,\n",
    "    \"precision\":precision, \n",
    "    \"recall\":recall,\n",
    "    \"f1\":f1,\n",
    "    \"sensitivity\":sensitivity,\n",
    "    \"specificity\":specificity,\n",
    "    \"kappa\":kappa\n",
    "    }\n",
    "    \n",
    "    return scores_for_grid\n",
    "\n",
    "\n",
    "def get_experiments_micro(true_label,pred_label):\n",
    "    \n",
    "     return  {\n",
    "    \"test_accuracy\":accuracy_score(true_label,pred_label ),\n",
    "    \"test_precision\":precision_score(true_label,pred_label , average='micro' ), \n",
    "    \"test_recall\":recall_score(true_label,pred_label , average='micro' ),\n",
    "    \"test_f1\":f1_score(true_label,pred_label , average='micro' ),\n",
    "    \"test_sensitivity\":sensitivity_score(true_label,pred_label , average='micro'),\n",
    "    \"test_specificity\":specificity_score(true_label,pred_label , average='micro'),\n",
    "    \"test_kappa\":cohen_kappa_score(true_label,pred_label  )\n",
    "     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NvX4TCiB3Zs"
   },
   "source": [
    "## model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJwXyA6PwnQO"
   },
   "source": [
    "### Time Distributed after LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NnRP6Qvisn0E"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense\n",
    "from keras.layers.recurrent import LSTM \n",
    "from keras.layers import Flatten, Dropout,RepeatVector,Activation, Dense , CuDNNLSTM \n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import  Adamax\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.regularizers import l2,l1_l2\n",
    "\n",
    "\n",
    "# https://medium.com/smileinnovation/how-to-work-with-time-distributed-data-in-a-neural-network-b8b39aa4ce00\n",
    "\n",
    "def make_model_LSTM_distribute_dense( ):\n",
    "  print('make_model_LSTM_distribute_dense in selected....')\n",
    "  \n",
    "\n",
    "  model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  from keras.layers import LeakyReLU\n",
    "  #from multiplicative_lstm import MultiplicativeLSTM   # recurrent_dropout=0.2,\n",
    "  model.add(  CuDNNLSTM(64,    kernel_regularizer= l2(0.001), return_sequences=True, input_shape=(1000, 3 ) )) #CuDNNLSTM\n",
    " \n",
    "  model.add(Dropout(0.37))\n",
    "\n",
    "\n",
    "  model.add(TimeDistributed( Dense( 64 )  )) \n",
    " \n",
    "\n",
    "\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(128 ))\n",
    "  \n",
    "  model.add(Dropout(.3))\n",
    "\n",
    "  # use N outputs\n",
    "  model.add(Dense( 2, activation='sigmoid'))\n",
    "\n",
    "  opt=Adamax(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-5) #*******************************\n",
    "\n",
    "  model.compile(loss='binary_crossentropy', optimizer=opt ,  metrics= ['binary_accuracy'  , precision_m, recall_m, f1_m, sensitivity_m, specificity_m  ])\n",
    "    \n",
    "\n",
    "  return model  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NdWWzcmUaVJW",
    "outputId": "21d276af-0269-4b05-ddaa-8e852f01d51a"
   },
   "outputs": [],
   "source": [
    "ss=make_model_LSTM_distribute_dense( )\n",
    "ss.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "igSfgMLqu2Or"
   },
   "source": [
    "### Model_Maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "id": "OMSSjhNwu005"
   },
   "outputs": [],
   "source": [
    "def Model_Maker( ):  \n",
    "  \n",
    "\n",
    "  return make_model_LSTM_distribute_dense() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "he6ydZETuYlR"
   },
   "source": [
    "## Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OnFdmyIuXRr"
   },
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    " \n",
    "\n",
    "   \n",
    "def make_pipeline():    \n",
    "\n",
    "    main_pipeline = Pipeline(steps =[\n",
    "        ('scaler',StandardScaler() ),           \n",
    "        ('Reshaping' , CustomLSTMReshaper()),         #                                                              , callbacks=callbacks_list    shuffle=True,            , callbacks=[rlrp ]\n",
    "        ('classifier', KerasClassifier(  build_fn=Model_Maker  , batch_size=512, verbose=1, epochs=1800    ))  # validation_split=0.3 \n",
    "        #,('freeUpMemory', freeUp_Memory() )     , callbacks=[rlrp, lrm]             , use_multiprocessing=True , validation_data=( X_val, y_val)\n",
    "    ],  verbose=True )\n",
    "    \n",
    "    return main_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "SE44B-tSXD9d"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "id": "YMkgKQnVXHFA"
   },
   "outputs": [],
   "source": [
    "from plot_keras_history import plot_history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Visualize_Result(mp , k, path ,  dbType): \n",
    "\n",
    "  #pip install plot_keras_history\n",
    "  #https://pypi.org/project/plot-keras-history/\n",
    "\n",
    "  estimator= mp['classifier'] \n",
    "  history=estimator.model.history.history\n",
    "\n",
    "\n",
    "  # plot_history(history)\n",
    "  # plt.show()\n",
    "\n",
    "  plot_history(history, path= path + dbType +\"_\"+ \"_fold(\"+ str(k) +\").png\" )\n",
    "  plt.close()\n",
    "  return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "J-hSY5oGoC2s"
   },
   "source": [
    "# post_Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "id": "WM3KGj50Z2Ud"
   },
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as pl\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def dict_mean(dict_list):\n",
    "  mean_dict = {}\n",
    "  std_dict = {}\n",
    "  \n",
    "\n",
    "  for key in dict_list[0].keys():\n",
    "      mean_dict[key] = np.mean([d[key] for d in dict_list], axis=0)\n",
    "      std_dict[key] = np.std([d[key] for d in dict_list], axis=0)\n",
    "      \n",
    "  return mean_dict, std_dict\n",
    "\n",
    "\n",
    "j=0 \n",
    "\n",
    "def Auto_All_History_plot(all_history, savepath , dbType):\n",
    "\n",
    "  result=dict_mean(all_history )\n",
    "\n",
    "  for val_metric_name in result[0]:\n",
    "    \n",
    "    if str( val_metric_name[0:4]) !='val_': # This is a condition for not calculating the results for both train and validation categories\n",
    "        break                               # Calculations are performed for train category and evaluation is also considered for validation\n",
    "\n",
    "    metric_name=str( val_metric_name[4:])\n",
    "\n",
    "\n",
    "    mean=result[0][ metric_name ] # mean\n",
    "    std=result[1][ metric_name ] #std\n",
    "\n",
    "\n",
    "    val_mean=result[0][ val_metric_name ] # mean\n",
    "    val_std=result[1][ val_metric_name ] #std\n",
    "\n",
    "\n",
    "    pl.plot(mean ,color='blue' ) #color='red'\n",
    "    pl.plot(val_mean ,color='red' )\n",
    "\n",
    "    pl.fill_between(  range(len(mean)) , mean-std, mean + std , alpha=0.3, label='Train' ,color='blue' )\n",
    "    pl.fill_between(  range(len(val_mean)) , val_mean-val_std, val_mean + val_std , alpha=0.3 , label='Validation' ,color='red' )\n",
    "\n",
    "    if str( metric_name[-2:] )=='_m':\n",
    "        metric_name=metric_name[:-2]\n",
    "    \n",
    "\n",
    "    plt.title( 'The Model '+metric_name+' Plot')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel( metric_name )\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    #pl.show()\n",
    "    plt.savefig( savepath+dbType+ '_'+ metric_name+'.png')\n",
    "    plt.close()\n",
    "\n",
    "  return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "fz35La2wB_E_"
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "id": "h9__qqxhVXWx"
   },
   "outputs": [],
   "source": [
    "# test Unseen data\n",
    "import pickle as pkl\n",
    "\n",
    "def LoadUnseenData():\n",
    "  \n",
    "  with open(basePath+'Imagery_temp_X_test_IV2A.pkl','rb') as f: #read\n",
    "    X_test = pkl.load(f)\n",
    "    \n",
    "  #print(X_test.shape)\n",
    "  \n",
    "\n",
    "  with open(basePath+'Imagery_temp_y_test_IV2A.pkl','rb') as f: #read\n",
    "    Y_test = pkl.load(f)\n",
    "    \n",
    "    \n",
    "    # karimian -- 1400 01 27\n",
    "    Y_test=[np.where(r==1)[0][0] for r in Y_test]\n",
    "    \n",
    "  #print(Y_test.shape)\n",
    "  print('-------------------------------------------')\n",
    "\n",
    "  return X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "U-m8GMo1CToC"
   },
   "source": [
    "# over_all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "id": "Elooi83OJjD7"
   },
   "outputs": [],
   "source": [
    "def over_all_metrics_stat(skf_metrics, savePath):\n",
    "  # Take mean and std over all folds \n",
    "  average_metrics_all_folds = dict(pd.DataFrame(skf_metrics).mean())\n",
    "  std_metrics_all_folds = dict(pd.DataFrame(skf_metrics).std())\n",
    "\n",
    "  \n",
    "\n",
    "  average_metrics_all_folds = {str( k[5:])+\"_avg_folds\":v for k,v in average_metrics_all_folds.items()}\n",
    "  std_metrics_all_folds = {str( k[5:])+\"_std_folds\":v for k,v in std_metrics_all_folds.items()}\n",
    "\n",
    "  print('_________ Training metric for all k-fold _________')\n",
    "  print('average_metrics_all_folds')\n",
    "  print(average_metrics_all_folds)\n",
    "  print()\n",
    "  print('std_metrics_all_folds')    \n",
    "  print(std_metrics_all_folds)\n",
    "  print()\n",
    "\n",
    "\n",
    "  df_average_metrics_all_folds = pd.DataFrame([average_metrics_all_folds])\n",
    "  df_std_metrics_all_folds = pd.DataFrame([std_metrics_all_folds])\n",
    "\n",
    "  pd.concat([df_average_metrics_all_folds, df_std_metrics_all_folds ],axis=1 ).to_csv( savePath + dbType + '_UnSeen_data_metric_avg_std.csv')\n",
    "\n",
    "\n",
    "  return     \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "qdRHc9ewBXdn"
   },
   "source": [
    "# k-fold Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "_8GcYyOfmQzF",
    "outputId": "50230d97-b0dd-436d-d2d6-6b8f8003f902"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_splits=5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=False ) #,random_state=random_seed\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "folds = {}\n",
    "count = 1\n",
    "for train_index, val_index in skf.split(X_train, y_train2 ):\n",
    "    folds['fold_{}'.format(count)] = {}\n",
    "    folds['fold_{}'.format(count)]['train_index'] = train_index.tolist()\n",
    "    folds['fold_{}'.format(count)]['val_index'] = val_index.tolist()\n",
    "    count += 1\n",
    "print(len(folds) == n_splits)#assert we have the same number of splits\n",
    "\n",
    "\n",
    "#dump folds to json\n",
    "# import json\n",
    "# with open( basePath+'folds.json', 'w') as fp:\n",
    "#     json.dump(folds, fp)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "CrL1ASO_msaU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Idu57K3Bv-Px"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "sGhnYhYOwJ84"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "yCLhu9U9o042",
    "outputId": "abd8bca3-f777-4173-fae7-85a9f287cd7a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from keras.utils.np_utils import to_categorical \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i=1\n",
    "\n",
    "for key, val in folds.items():\n",
    "\n",
    "\n",
    "  print(key)\n",
    "  print(i)\n",
    "\n",
    "  train_index = val['train_index']\n",
    "  val_index = val['val_index']\n",
    "\n",
    "\n",
    "  \n",
    "  skf_X_train, skf_X_val = (pd.DataFrame( X_train )).iloc[train_index], (pd.DataFrame( X_train)).iloc[val_index]\n",
    "  skf_y_train, skf_y_val = (pd.DataFrame( y_train2 )).iloc[train_index], (pd.DataFrame( y_train2 )).iloc[val_index]\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "  with open( basePath + 'kfold_data_variable ('+ str(i) +').pkl', 'wb') as p: \n",
    "      pickle.dump([ skf_X_train, skf_X_val, skf_y_train, skf_y_val  ], p)\n",
    "\n",
    "\n",
    "  print('_step_',i)\n",
    "  i+=1\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zl31eNvfBbD1"
   },
   "source": [
    "# k-fold Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu7j-71qH7E3",
    "outputId": "19cde65b-a790-4116-da08-88189c191b6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var empty mod\n"
     ]
    }
   ],
   "source": [
    "# load previous config\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "try:\n",
    "  with open(basePath + dbType +'_Kfold_Imagery_all_history.pkl','rb') as f: #read\n",
    "    all_history = pkl.load(f)\n",
    "\n",
    "  with open(basePath + dbType+ '_UnSeen_data_metric_avg_std.pkl','rb') as f: #read\n",
    "    skf_metrics = pkl.load(f)\n",
    "\n",
    "\n",
    "except:\n",
    "  print('var empty mod')\n",
    "  all_history= []\n",
    "  skf_metrics= []\n",
    " \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNOpWwyZD0xF"
   },
   "source": [
    "# Main Excutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oZYGO1J0yKhG",
    "outputId": "29270b11-7f8d-4db5-cd56-d5c645751c24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(all_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JI9dq7aTqM1m",
    "outputId": "5cb4e84f-88b2-48f6-eb93-7e4ca3088efb"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ RUN ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "import pandas as pd\n",
    "import gc\n",
    "from keras.utils.np_utils import to_categorical \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "i=1 # part number in k- fold [1,2,3,4,5]\n",
    "\n",
    "\n",
    "with open( basePath + 'kfold_data_variable ('+ str( i) +').pkl' ,'rb') as p:   \n",
    "    skf_X_train, skf_X_val, skf_y_train, skf_y_val  = pickle.load(p)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "print(\"============ Training on fold ({}) ==============\".format(i))\n",
    "\n",
    "#skf_y_val2=[np.where(r==1)[0][0] for r in np.array(skf_y_val) ]\n",
    "\n",
    "\n",
    "skf_y_train2= to_categorical( skf_y_train , num_classes=2)\n",
    "skf_y_val2= to_categorical( skf_y_val , num_classes=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pipeline = make_pipeline( ) \n",
    "\n",
    "# ------------------------\n",
    "pipeline.named_steps['scaler'].fit(skf_X_train)\n",
    "skf_X_val22=pipeline.named_steps['scaler'].transform(skf_X_val)\n",
    "skf_X_val2=pipeline.named_steps['Reshaping'].transform(skf_X_val22)\n",
    "# ------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pipeline.fit(skf_X_train, skf_y_train2 , classifier__validation_data=( skf_X_val2, skf_y_val2)  )\n",
    "\n",
    "gc.collect()\n",
    "del skf_X_train, skf_y_train, skf_y_val, skf_y_train2, skf_y_val2, skf_X_val2, skf_X_val22, skf_X_val\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test, Y_test =LoadUnseenData()\n",
    "\n",
    "y_pred_val = pipeline.predict( X_test  )\n",
    "del X_test\n",
    "gc.collect()\n",
    "\n",
    "print(\"_________________________________________________\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('___step___',i)\n",
    "print()\n",
    "print('Model Evaluation is in process...')\n",
    "test_results = get_experiments( Y_test , y_pred_val)\n",
    "print(test_results)\n",
    "del Y_test , y_pred_val\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "skf_metrics.append(test_results)\n",
    "\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "all_history.append( pipeline['classifier'].model.history.history )\n",
    "print('Model Training history has been store')\n",
    "print()\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "Visualize_Result(pipeline , i, basePath ,   dbType )\n",
    "print('Evaluation Resault has been Visualized')\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "# # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "del pipeline\n",
    "gc.collect()\n",
    "\n",
    "# # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "with open(basePath + dbType +'_Kfold_Imagery_all_history.pkl','wb') as f: #write\n",
    "  pkl.dump( all_history , f)\n",
    "print('Model Training history Resault has been wrote on file')\n",
    "\n",
    "\n",
    "with open(basePath + dbType +'_UnSeen_data_metric_avg_std.pkl','wb') as f: #write\n",
    "  pkl.dump( skf_metrics , f)\n",
    "print('Model Evaliuation Resault has been wrote on file')  \n",
    "\n",
    "\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-oTLcvLGYBH"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "over_all_metrics_stat(skf_metrics, basePath)\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "pd.DataFrame([all_history]).to_csv( basePath+ dbType+'_All_history.csv')\n",
    "\n",
    "Auto_All_History_plot( all_history , basePath ,dbType)\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "df = pd.DataFrame( skf_metrics, columns=['test_accuracy', 'test_precision', 'test_recall' ,'test_f1' , 'test_specificity', 'test_sensitivity', 'test_kappa' ])\n",
    "pd.DataFrame( df ).to_csv( basePath + dbType + '_All_UnseenData_Results_df.csv' , index=False )\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "print(' .: Model Training has been finished successfully :. ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "Oi-Bnq7kKj6B"
   },
   "source": [
    "# save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "bTDNzw99u20i"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from keras.models import load_model\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "...\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('estimator', KerasRegressor(build_model))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save the Keras model first:\n",
    "pipeline.named_steps['estimator'].model.save('keras_model.h5')\n",
    "\n",
    "# This hack allows us to save the sklearn pipeline:\n",
    "pipeline.named_steps['estimator'].model = None\n",
    "\n",
    "# Finally, save the pipeline:\n",
    "joblib.dump(pipeline, 'sklearn_pipeline.pkl')\n",
    "\n",
    "del pipeline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the pipeline first:\n",
    "pipeline = joblib.load('sklearn_pipeline.pkl')\n",
    "\n",
    "# Then, load the Keras model:\n",
    "pipeline.named_steps['estimator'].model = load_model('keras_model.h5')\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "g1yQ_BwRRgXy"
   },
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "# Save the Keras model first:\n",
    "# mp.named_steps['classifier'].model.save('/content/drive/My Drive/SA_NTM_990922/EEG_Model_Classification_model.h5')\n",
    "\n",
    "# This hack allows us to save the sklearn pipeline:\n",
    "#pipeline.named_steps['estimator'].model = None\n",
    "\n",
    "# Finally, save the pipeline:\n",
    "#joblib.dump( mp , '/content/drive/My Drive/SA_NTM_990922/EEG_Model_Classification_pipeline.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Wkhd3yvbYCHK"
   },
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# with open('/content/drive/My Drive/SA_NTM_990922/history.pkl','wb') as f: #write\n",
    "#     pkl.dump( d , f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "udstZZR2KpDJ"
   },
   "outputs": [],
   "source": [
    "  # import pickle as pkl\n",
    "  # with open('/content/drive/My Drive/SA_NTM_990922/history.pkl','rb') as f: #read\n",
    "  #   history = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "DJjNtmwiUQvf"
   },
   "outputs": [],
   "source": [
    "# load model & pipeline\n",
    "# from keras.models import load_model\n",
    "# from sklearn.externals import joblib\n",
    "\n",
    "# from multiplicative_lstm import MultiplicativeLSTM\n",
    "\n",
    "\n",
    "# # Load the pipeline first:\n",
    "# pipeline = joblib.load('./EEG_Model_Classification_pipeline.pkl')\n",
    "\n",
    "# # Then, load the Keras model:\n",
    "# pipeline.named_steps['estimator'].model = load_model('./EEG_Model_Classification_model.h5')\n",
    "\n",
    "# y_pred = pipeline.predict(~temp_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "8X-L5RoGR9tU"
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "\n",
    "# print('start data section') \n",
    "# gc.collect()                                                  \n",
    "# X_train,X_test, Y_train, Y_test= Load_data()\n",
    "# gc.collect()\n",
    "# print('finish data section')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#y_train3 = tf.keras.utils.to_categorical(y_train2, 4)\n",
    "\n",
    "# model=make_model(batch_size)\n",
    "# #y_train3\n",
    "# history=model.fit(X_train7, y_train, validation_split=0.28125, epochs=25, batch_size=batch_size, verbose=1 ) #, callbacks=[tensorboard_callback]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "zqGdGHemVDbZ"
   },
   "outputs": [],
   "source": [
    "print(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "WKIuq0lSdiTI"
   },
   "outputs": [],
   "source": [
    "del X_train7, y_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "s3vcAUgSSkre",
    "outputId": "dd8d0723-5e4d-4254-c7e9-be4afe5b28fe"
   },
   "outputs": [],
   "source": [
    "with open('~temp_X_test_02.pkl','rb') as f: #read\n",
    "  _X_test = pkl.load(f)\n",
    "  \n",
    "print(_X_test.shape)\n",
    "print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "EXSmrvbuYdCB"
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "\n",
    "# Y_pred = mp.predict(X_test)\n",
    "# test_results = get_experiments(Y_test,Y_pred)\n",
    "\n",
    "estimator= mp['classifier'] \n",
    "d=estimator.model #.history.history\n",
    "\n",
    "#estimator.model.history.history\n",
    "#print(a.model.history.history)\n",
    "\n",
    "import tensorflow as tf\n",
    "Y_test2 = tf.keras.utils.to_categorical(Y_test, 2)\n",
    "\n",
    "# حتمن باید استاندارد اسکالر هم اعمال شود\n",
    "X_test3=X_test.reshape(( len(X_test) ,80,64 ))\n",
    "\n",
    "\n",
    "print(\"Evaluation....\")\n",
    "score= d.evaluate(X_test3, Y_test2, batch_size=1024, verbose=1)                                           \n",
    "\n",
    "\n",
    "print('Training results')\n",
    "print('-------------------------------------------')\n",
    "print('Training loss:', score[0])\n",
    "print('Training accuracy:', score[1])\n",
    "print('-------------------------------------------')    \n",
    "print('*********** finish *************')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "21nfqexC_trs"
   },
   "outputs": [],
   "source": [
    "print(Y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1EODUBQj-zPU",
    "h11kVYItZ-qn",
    "aTb_J9rhuBs6",
    "JiZUQk7CYqN0",
    "Fjo7iI5D3Rt8",
    "igSfgMLqu2Or",
    "SE44B-tSXD9d",
    "J-hSY5oGoC2s",
    "fz35La2wB_E_",
    "U-m8GMo1CToC",
    "qdRHc9ewBXdn",
    "Oi-Bnq7kKj6B"
   ],
   "name": "IV2A_Imagery_14000514_PM+.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
